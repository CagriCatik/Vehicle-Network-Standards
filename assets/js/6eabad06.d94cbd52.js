"use strict";(self.webpackChunkvns=self.webpackChunkvns||[]).push([[18320],{85430:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"FMEA/chapter_9/4","title":"Stage 03: Specifying the Detectability of Failure","description":"Q1: What is Stage 03 in the FMEA process?","source":"@site/docs/FMEA/chapter_9/4.md","sourceDirName":"FMEA/chapter_9","slug":"/FMEA/chapter_9/4","permalink":"/Vehicle-Network-Standards/docs/FMEA/chapter_9/4","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/FMEA/chapter_9/4.md","tags":[],"version":"current","frontMatter":{},"sidebar":"fmeaSidebar","previous":{"title":"Stage 02: Specifying the Occurrence of Failure","permalink":"/Vehicle-Network-Standards/docs/FMEA/chapter_9/3"},"next":{"title":"Stage 04 and 05: Quantifying Risk and Correcting High-Risk Situations","permalink":"/Vehicle-Network-Standards/docs/FMEA/chapter_9/5"}}');var s=i(74848),r=i(28453);const a={},o="Stage 03: Specifying the Detectability of Failure",c={},l=[];function d(e){const t={br:"br",h1:"h1",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"stage-03-specifying-the-detectability-of-failure",children:"Stage 03: Specifying the Detectability of Failure"})}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Q1: What is Stage 03 in the FMEA process?"}),(0,s.jsx)(t.br,{}),"\n",(0,s.jsx)(t.strong,{children:"A1:"})," Stage 03 focuses on specifying the detectability of failure modes. In this stage, the team evaluates how likely it is that a failure mode will be detected by existing process controls before it impacts the customer or causes significant harm."]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:'Q2: What does "detectability" mean in the context of FMEA?'}),(0,s.jsx)(t.br,{}),"\n",(0,s.jsx)(t.strong,{children:"A2:"})," Detectability in FMEA refers to the ability of current process controls\u2014such as inspections, monitoring systems, and testing procedures\u2014to identify a failure mode after it has occurred, but before it results in adverse effects. It is an independent measure from the occurrence of the failure."]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Q3: Why is specifying detectability important in FMEA?"}),(0,s.jsx)(t.br,{}),"\n",(0,s.jsx)(t.strong,{children:"A3:"})," Specifying detectability is critical because it helps determine the effectiveness of the controls in place to catch failures early. This assessment directly influences the Risk Priority Number (RPN) by ensuring that even if a failure mode occurs, it will be identified promptly, thereby minimizing its potential impact."]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Q4: How is the detectability rating typically measured?"}),(0,s.jsx)(t.br,{}),"\n",(0,s.jsx)(t.strong,{children:"A4:"})," The detectability rating is usually measured on a numerical scale (commonly from 1 to 10):"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["A rating of ",(0,s.jsx)(t.strong,{children:"1"})," indicates that the failure mode is almost certain to be detected (i.e., very effective detection)."]}),"\n",(0,s.jsxs)(t.li,{children:["A rating of ",(0,s.jsx)(t.strong,{children:"10"})," means that the failure mode is almost impossible to detect (i.e., very poor detection capability)."]}),"\n"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Q5: What factors are considered when assigning a detectability rating?"}),(0,s.jsx)(t.br,{}),"\n",(0,s.jsx)(t.strong,{children:"A5:"})," When assigning a detectability rating, factors include:"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"The sensitivity of the detection methods."}),"\n",(0,s.jsx)(t.li,{children:"The frequency and thoroughness of inspections or monitoring."}),"\n",(0,s.jsx)(t.li,{children:"The reliability of detection systems or controls."}),"\n",(0,s.jsx)(t.li,{children:"Historical performance data on detection effectiveness.\nThese factors help determine how likely it is that a failure mode will be caught before causing harm."}),"\n"]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Q6: How does the detectability rating impact the overall Risk Priority Number (RPN)?"}),(0,s.jsx)(t.br,{}),"\n",(0,s.jsx)(t.strong,{children:"A6:"})," The detectability rating is one of the three components in the RPN calculation (RPN = Severity \xd7 Occurrence \xd7 Detectability). A higher detectability rating (indicating poor detection capability) increases the RPN, signaling a higher overall risk. Conversely, a low detectability rating (indicating strong detection controls) reduces the RPN."]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Q7: Can you provide an example of a failure mode with a detectability rating of 1?"}),(0,s.jsx)(t.br,{}),"\n",(0,s.jsx)(t.strong,{children:"A7:"})," An example of a failure mode with a detectability rating of 1 might be a process where automated sensors and regular inspections almost always identify issues immediately after they occur. This means that detection is nearly guaranteed, resulting in the best possible rating for detectability."]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Q8: Why must detectability be evaluated independently from occurrence?"}),(0,s.jsx)(t.br,{}),"\n",(0,s.jsx)(t.strong,{children:"A8:"})," Detectability must be evaluated independently because it focuses solely on the effectiveness of the controls to catch a failure mode, regardless of how frequently that failure occurs. A failure mode could be rare but still require a robust detection system to prevent severe consequences if it does happen."]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Q9: How does a multidisciplinary team contribute to determining accurate detectability ratings?"}),(0,s.jsx)(t.br,{}),"\n",(0,s.jsx)(t.strong,{children:"A9:"})," A multidisciplinary team brings diverse perspectives and expertise in detection methods, quality control, and process operations. This collaboration helps ensure that detectability ratings are comprehensive, objective, and reflective of real-world conditions, reducing the subjectivity in the evaluation process."]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Q10: What challenges might arise when specifying the detectability of a failure mode?"}),(0,s.jsx)(t.br,{}),"\n",(0,s.jsx)(t.strong,{children:"A10:"})," Challenges include:"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Subjectivity:"})," Different team members might have varying opinions on the effectiveness of detection methods."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Data Limitations:"})," In some cases, there may be insufficient historical data to accurately gauge detection capability."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Changing Conditions:"})," Variability in operational or environmental conditions can affect how reliably a failure mode is detected.\nAddressing these challenges requires a structured evaluation process and ongoing collaboration among team members."]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,t,i)=>{i.d(t,{R:()=>a,x:()=>o});var n=i(96540);const s={},r=n.createContext(s);function a(e){const t=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),n.createElement(r.Provider,{value:t},e.children)}}}]);